/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
[09/16 00:57:23 detectron2]: Rank of current process: 0. World size: 4
[09/16 00:57:23 detectron2]: Full config saved to checkpoints/coco/1726444636/base/config.yaml
[09/16 00:57:24 detectron2]: [Refine] n = 24, α = 0.1
[09/16 00:57:35 d2.data.build]: Removed 13846 images with no usable annotations. 68937 images left.
[09/16 00:57:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 00:57:35 d2.data.build]: Using training sampler TrainingSampler
[09/16 00:57:36 d2.data.common]: Serializing 68937 elements to byte tensors and concatenating them all ...
[09/16 00:57:36 d2.data.common]: Serialized dataset takes 30.91 MiB
[09/16 00:57:37 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 00:57:37 fvcore.common.checkpoint]: Reading a file from 'torchvision'
WARNING [09/16 00:57:37 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
refine.centroids
refine.fc.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
WARNING [09/16 00:57:37 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[09/16 00:57:37 d2.engine.train_loop]: Starting training from iteration 0
/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 30, in main
    return trainer.train()
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 484, in train
    super().train(self.start_iter, self.max_iter)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 886, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users/acr23hk/paper/fsod-dc/src/modeling/rcnn.py", line 55, in forward
    _, detector_losses = self.roi_heads(features_refined, proposals)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users/acr23hk/paper/fsod-dc/src/modeling/roi_heads.py", line 112, in forward
    predictions = self.box_predictor(box_features.mean(dim=[2, 3]))
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users/acr23hk/paper/fsod-dc/src/modeling/roi_heads.py", line 66, in forward
    scores = self.apply_self_distillation(scores, x)
  File "/users/acr23hk/paper/fsod-dc/src/modeling/roi_heads.py", line 75, in apply_self_distillation
    centroids_sim = self.compute_centroids_sim(features)
  File "/users/acr23hk/paper/fsod-dc/src/modeling/roi_heads.py", line 84, in compute_centroids_sim
    normalized_features = F.normalize(features, dim=1)
NameError: name 'F' is not defined

Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/users/acr23hk/paper/fsod-dc/tools/ckpt_surgery.py", line 128, in <module>
    main(args)
  File "/users/acr23hk/paper/fsod-dc/tools/ckpt_surgery.py", line 83, in main
    sd = torch.load(inp_path, map_location="cpu")
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/users/acr23hk/paper/fsod-dc/checkpoints/coco/1726444636/base/model_final.pth'
/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
/users/acr23hk/.conda/envs/paper1/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 56 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
[09/16 00:58:06 detectron2]: Rank of current process: 0. World size: 4
[09/16 00:58:06 detectron2]: Full config saved to checkpoints/coco/1726444636/fsod/1shot/seed1/config.yaml
[09/16 00:58:07 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 00:58:07 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[09/16 00:58:18 detectron2]: Loss: 0.0002
[09/16 00:58:18 detectron2]: [CLS] Use dropout: p = 0.8
[09/16 00:58:18 detectron2]: [Refine] n = 24, α = 0.1
[09/16 00:58:18 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.
[09/16 00:58:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 00:58:18 d2.data.build]: Using training sampler TrainingSampler
[09/16 00:58:18 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...
[09/16 00:58:18 d2.data.common]: Serialized dataset takes 0.02 MiB
[09/16 00:58:18 fvcore.common.checkpoint]: [Checkpointer] Loading from checkpoints/coco/1726444636/base/model_final-fsod.pth ...
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 29, in main
    trainer.resume_or_load(resume=args.resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 412, in resume_or_load
    self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 227, in resume_or_load
    return self.load(path, checkpointables=[])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/checkpoint/detection_checkpoint.py", line 52, in load
    ret = super().load(path, *args, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 153, in load
    assert os.path.isfile(path), "Checkpoint {} not found!".format(path)
AssertionError: Checkpoint checkpoints/coco/1726444636/base/model_final-fsod.pth not found!

/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
[09/16 00:58:27 detectron2]: Rank of current process: 0. World size: 4
[09/16 00:58:27 detectron2]: Full config saved to checkpoints/coco/1726444636/fsod/2shot/seed1/config.yaml
[09/16 00:58:28 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 00:58:28 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[09/16 00:58:43 detectron2]: Loss: 0.0009
[09/16 00:58:43 detectron2]: [CLS] Use dropout: p = 0.8
[09/16 00:58:43 detectron2]: [Refine] n = 24, α = 0.1
[09/16 00:58:43 d2.data.build]: Removed 0 images with no usable annotations. 160 images left.
[09/16 00:58:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 00:58:43 d2.data.build]: Using training sampler TrainingSampler
[09/16 00:58:44 d2.data.common]: Serializing 160 elements to byte tensors and concatenating them all ...
[09/16 00:58:44 d2.data.common]: Serialized dataset takes 0.04 MiB
[09/16 00:58:44 fvcore.common.checkpoint]: [Checkpointer] Loading from checkpoints/coco/1726444636/base/model_final-fsod.pth ...
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 29, in main
    trainer.resume_or_load(resume=args.resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 412, in resume_or_load
    self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 227, in resume_or_load
    return self.load(path, checkpointables=[])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/checkpoint/detection_checkpoint.py", line 52, in load
    ret = super().load(path, *args, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 153, in load
    assert os.path.isfile(path), "Checkpoint {} not found!".format(path)
AssertionError: Checkpoint checkpoints/coco/1726444636/base/model_final-fsod.pth not found!

/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
[09/16 00:58:52 detectron2]: Rank of current process: 0. World size: 4
[09/16 00:58:52 detectron2]: Full config saved to checkpoints/coco/1726444636/fsod/3shot/seed1/config.yaml
[09/16 00:58:53 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 00:58:53 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[09/16 00:59:11 detectron2]: Loss: 0.0016
[09/16 00:59:11 detectron2]: [CLS] Use dropout: p = 0.8
[09/16 00:59:11 detectron2]: [Refine] n = 24, α = 0.1
[09/16 00:59:11 d2.data.build]: Removed 0 images with no usable annotations. 240 images left.
[09/16 00:59:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 00:59:11 d2.data.build]: Using training sampler TrainingSampler
[09/16 00:59:11 d2.data.common]: Serializing 240 elements to byte tensors and concatenating them all ...
[09/16 00:59:11 d2.data.common]: Serialized dataset takes 0.07 MiB
[09/16 00:59:11 fvcore.common.checkpoint]: [Checkpointer] Loading from checkpoints/coco/1726444636/base/model_final-fsod.pth ...
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 29, in main
    trainer.resume_or_load(resume=args.resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 412, in resume_or_load
    self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 227, in resume_or_load
    return self.load(path, checkpointables=[])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/checkpoint/detection_checkpoint.py", line 52, in load
    ret = super().load(path, *args, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 153, in load
    assert os.path.isfile(path), "Checkpoint {} not found!".format(path)
AssertionError: Checkpoint checkpoints/coco/1726444636/base/model_final-fsod.pth not found!

/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
[09/16 00:59:20 detectron2]: Rank of current process: 0. World size: 4
[09/16 00:59:20 detectron2]: Full config saved to checkpoints/coco/1726444636/fsod/5shot/seed1/config.yaml
[09/16 00:59:21 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 00:59:21 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[09/16 00:59:48 detectron2]: Loss: 0.0031
[09/16 00:59:48 detectron2]: [CLS] Use dropout: p = 0.8
[09/16 00:59:48 detectron2]: [Refine] n = 24, α = 0.1
[09/16 00:59:48 d2.data.build]: Removed 0 images with no usable annotations. 385 images left.
[09/16 00:59:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 00:59:48 d2.data.build]: Using training sampler TrainingSampler
[09/16 00:59:49 d2.data.common]: Serializing 385 elements to byte tensors and concatenating them all ...
[09/16 00:59:49 d2.data.common]: Serialized dataset takes 0.11 MiB
[09/16 00:59:49 fvcore.common.checkpoint]: [Checkpointer] Loading from checkpoints/coco/1726444636/base/model_final-fsod.pth ...
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 29, in main
    trainer.resume_or_load(resume=args.resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 412, in resume_or_load
    self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 227, in resume_or_load
    return self.load(path, checkpointables=[])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/checkpoint/detection_checkpoint.py", line 52, in load
    ret = super().load(path, *args, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 153, in load
    assert os.path.isfile(path), "Checkpoint {} not found!".format(path)
AssertionError: Checkpoint checkpoints/coco/1726444636/base/model_final-fsod.pth not found!

/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
[09/16 00:59:58 detectron2]: Rank of current process: 0. World size: 4
[09/16 00:59:58 detectron2]: Full config saved to checkpoints/coco/1726444636/fsod/10shot/seed1/config.yaml
[09/16 00:59:59 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 00:59:59 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[09/16 01:00:43 detectron2]: Loss: 0.0076
[09/16 01:00:43 detectron2]: [CLS] Use dropout: p = 0.8
[09/16 01:00:43 detectron2]: [Refine] n = 24, α = 0.1
[09/16 01:00:43 d2.data.build]: Removed 0 images with no usable annotations. 692 images left.
[09/16 01:00:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 01:00:43 d2.data.build]: Using training sampler TrainingSampler
[09/16 01:00:43 d2.data.common]: Serializing 692 elements to byte tensors and concatenating them all ...
[09/16 01:00:43 d2.data.common]: Serialized dataset takes 0.20 MiB
[09/16 01:00:43 fvcore.common.checkpoint]: [Checkpointer] Loading from checkpoints/coco/1726444636/base/model_final-fsod.pth ...
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 29, in main
    trainer.resume_or_load(resume=args.resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 412, in resume_or_load
    self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 227, in resume_or_load
    return self.load(path, checkpointables=[])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/checkpoint/detection_checkpoint.py", line 52, in load
    ret = super().load(path, *args, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 153, in load
    assert os.path.isfile(path), "Checkpoint {} not found!".format(path)
AssertionError: Checkpoint checkpoints/coco/1726444636/base/model_final-fsod.pth not found!

/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/setuptools/_distutils/version.py
[09/16 01:00:52 detectron2]: Rank of current process: 0. World size: 4
[09/16 01:00:52 detectron2]: Full config saved to checkpoints/coco/1726444636/fsod/30shot/seed1/config.yaml
[09/16 01:00:53 fvcore.common.checkpoint]: [Checkpointer] Loading from ./pretrain/R-101.pkl ...
[09/16 01:00:53 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[09/16 01:02:33 detectron2]: Loss: 0.0109
[09/16 01:02:33 detectron2]: [CLS] Use dropout: p = 0.8
[09/16 01:02:33 detectron2]: [Refine] n = 24, α = 0.1
[09/16 01:02:33 d2.data.build]: Removed 0 images with no usable annotations. 1665 images left.
[09/16 01:02:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=1333, sample_style='choice'), RandomFlip()]
[09/16 01:02:33 d2.data.build]: Using training sampler TrainingSampler
[09/16 01:02:33 d2.data.common]: Serializing 1665 elements to byte tensors and concatenating them all ...
[09/16 01:02:33 d2.data.common]: Serialized dataset takes 0.51 MiB
[09/16 01:02:33 fvcore.common.checkpoint]: [Checkpointer] Loading from checkpoints/coco/1726444636/base/model_final-fsod.pth ...
Traceback (most recent call last):
  File "main.py", line 38, in <module>
    launch(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/users/acr23hk/paper/fsod-dc/main.py", line 29, in main
    trainer.resume_or_load(resume=args.resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 412, in resume_or_load
    self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 227, in resume_or_load
    return self.load(path, checkpointables=[])
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/detectron2/checkpoint/detection_checkpoint.py", line 52, in load
    ret = super().load(path, *args, **kwargs)
  File "/users/acr23hk/.conda/envs/paper1/lib/python3.8/site-packages/fvcore/common/checkpoint.py", line 153, in load
    assert os.path.isfile(path), "Checkpoint {} not found!".format(path)
AssertionError: Checkpoint checkpoints/coco/1726444636/base/model_final-fsod.pth not found!

